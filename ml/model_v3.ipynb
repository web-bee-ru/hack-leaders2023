{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd # 2.x to support pyarrow\n",
    "import pyarrow as pa\n",
    "import openpyxl # for reading xlsx with structure\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import math\n",
    "import re\n",
    "from datetime import timedelta, datetime\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_structure = pd.read_parquet('../data/pipeline/x_structure.parquet')\n",
    "y_structure = pd.read_parquet('../data/pipeline/y_structure.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_pretty_1h = pd.read_parquet('../data/pipeline/x_train_pretty_1h.parquet')\n",
    "x_test_pretty_1h = pd.read_parquet('../data/pipeline/x_test_pretty_1h.parquet')\n",
    "y_train_tte_1h = pd.read_parquet('../data/pipeline/y_train_tte_1h.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "left = x_train_pretty_1h.set_index(['ИМЯ МАШИНЫ', 'DT']).astype('float64').sort_index().ffill()[x_structure.index]\n",
    "left_test = x_test_pretty_1h.set_index(['ИМЯ МАШИНЫ', 'DT']).astype('float64').sort_index().ffill()[x_structure.index]\n",
    "left_test_raw = x_test_pretty_1h.set_index(['ИМЯ МАШИНЫ', 'DT']).astype('float64').sort_index()[x_structure.index]\n",
    "\n",
    "left_stats = left.describe()\n",
    "\n",
    "left = left / left_stats.loc['std']\n",
    "left_test = left_test / left_stats.loc['std']\n",
    "\n",
    "MAX_TTE = 31 * 24 * 60 * 60"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model = keras.Sequential([\n",
    "#     keras.Input((24*7, len(x_structure.index))),\n",
    "#     keras.layers.Dense(len(y_structure.index)*3, activation='relu'),\n",
    "#     keras.layers.Dense(len(y_structure.index)*2, activation='relu'),\n",
    "#     keras.layers.Dense(len(y_structure.index), activation='sigmoid'),\n",
    "# ])\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = left.index.levels[1]\n",
    "split_left = index[int(0.7 * len(index))]\n",
    "split_right = index[int(0.7 * len(index)) + 1]\n",
    "\n",
    "left_train = left.loc[pd.IndexSlice[:, :split_left], :]\n",
    "left_val = left.loc[pd.IndexSlice[:, split_right:], :]\n",
    "\n",
    "display((len(left_train), len(left_val)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @WIP: Гидра\n",
    "\n",
    "# right = y_train_tte_1h.set_index(['ИМЯ МАШИНЫ', 'DT']).astype('float64') / MAX_TTE\n",
    "# right_train = right.loc[pd.IndexSlice[:, :split_left], :]\n",
    "# right_val = right.loc[pd.IndexSlice[:, split_right:], :]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sequence_length = 24 * 7\n",
    "sequence_stride = 24\n",
    "\n",
    "def prepare_batches(data):\n",
    "    batches = None\n",
    "    for machine in x_structure.columns:\n",
    "        seq = data.loc[machine].sort_index().astype('float64').ffill().fillna(0)\n",
    "        X = seq[x_structure.index]\n",
    "        Y = seq.drop(x_structure.index, axis=1)\n",
    "\n",
    "        inputs = keras.utils.timeseries_dataset_from_array(\n",
    "            X, None, batch_size=64,\n",
    "            sequence_length=sequence_length,\n",
    "            sequence_stride=sequence_stride,\n",
    "            seed=1337,\n",
    "        )\n",
    "        targets = keras.utils.timeseries_dataset_from_array(\n",
    "            Y, None, batch_size=64,\n",
    "            sequence_length=sequence_length,\n",
    "            sequence_stride=sequence_stride,\n",
    "            seed=1337,\n",
    "        )\n",
    "        machine_examples = tf.data.Dataset.zip((inputs, targets))\n",
    "\n",
    "        if batches is None:\n",
    "            batches = machine_examples\n",
    "        else:\n",
    "            batches = batches.concatenate(machine_examples)\n",
    "    return batches\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "loss_a = 30\n",
    "metric_a = 30\n",
    "\n",
    "def wrmse_loss(y_true, y_pred):\n",
    "    loss = keras.backend.square(y_pred - y_true)  # (batch_size, 2)\n",
    "    t = y_true\n",
    "    a = loss_a\n",
    "    weights = 1 / (keras.backend.clip(a * t, 1, a)) # @NOTE: clip чтобы не получать бесконечности когда t стремится к 0\n",
    "    loss *= weights\n",
    "    loss = keras.backend.mean(loss, axis=1)        # (batch_size,)\n",
    "    return loss\n",
    "\n",
    "def wrmse_metric(y_true, y_pred):\n",
    "    t = y_true\n",
    "    a = metric_a\n",
    "    weights = 1 / ((a * t).clip(lower=1)) # @NOTE: clip чтобы не получать бесконечности когда t стремится к 0\n",
    "    e = y_pred - y_true\n",
    "    se = e ** 2\n",
    "    wse = se * weights\n",
    "    wmse: pd.DataFrame = wse.mean()\n",
    "    wrmse = wmse ** 0.5\n",
    "    average_wrmse = wrmse\n",
    "    # average_wrmse = wrmse.mean() # @WIP: Гидра\n",
    "    return wrmse[0]\n",
    "\n",
    "def train_model(target_place_name_and_type):\n",
    "    model_path = f'../dist/models_v3/{target_place_name_and_type}.h5'\n",
    "\n",
    "    # if os.path.isfile(model_path):\n",
    "    #     return\n",
    "\n",
    "    right = y_train_tte_1h.set_index(['ИМЯ МАШИНЫ', 'DT'])[[target_place_name_and_type]].astype('float64') / MAX_TTE\n",
    "    right_train = right.loc[pd.IndexSlice[:, :split_left], :]\n",
    "    right_val = right.loc[pd.IndexSlice[:, split_right:], :]\n",
    "\n",
    "    train_data = pd.merge(left_train, right_train, left_index=True, right_index=True)\n",
    "    val_data = pd.merge(left_val, right_val, left_index=True, right_index=True)\n",
    "\n",
    "    train_batches = prepare_batches(train_data)\n",
    "    val_batches = prepare_batches(val_data)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.Input((sequence_length, len(x_structure.index))),\n",
    "        # keras.layers.Dense(sequence_length * len(x_structure.index) / 4, activation='leaky_relu'),\n",
    "        keras.layers.Dense(24*3, activation='leaky_relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid'),\n",
    "    ])\n",
    "\n",
    "    # model.compile(loss=wrmse_loss, optimizer='adam', metrics=[\"mae\"])\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=[\"mae\"])\n",
    "    # model.summary()\n",
    "    #\n",
    "    print(str(datetime.now()) + ' -- ' + target_place_name_and_type)\n",
    "\n",
    "    train_batch_idx = 6\n",
    "    train_sample_idx = 60\n",
    "    x_train_demos, y_train_demos = list(train_batches)[train_batch_idx]\n",
    "    x_train_demo = x_train_demos[train_sample_idx]\n",
    "    y_train_demo = y_train_demos[train_sample_idx]\n",
    "\n",
    "    val_batch_idx = 13\n",
    "    val_sample_idx = 6\n",
    "    x_val_demos, y_val_demos = list(val_batches)[val_batch_idx]\n",
    "    x_val_demo = x_val_demos[val_sample_idx]\n",
    "    y_val_demo = y_val_demos[val_sample_idx]\n",
    "\n",
    "    # history = model.fit(train_batches, validation_data=val_batches, epochs=0)\n",
    "    history = model.fit(train_batches, validation_data=val_batches, epochs=100)\n",
    "    # history = model.fit(np.array(x_train_demos), np.array(y_train_demos), validation_data=(x_val_demos, y_val_demos), epochs=1000)\n",
    "    # history = model.fit(np.array([x_train_demo]), np.array([y_train_demo]), epochs=1000)\n",
    "\n",
    "    # model.save(model_path, save_format='h5')\n",
    "    # return model, history, (x_train_demo, y_train_demo)\n",
    "    return model, history, (x_val_demo, y_val_demo)\n",
    "\n",
    "model_v1 = keras.models.load_model(f'../dist/models/РОТОР TTE M3.h5', compile=False)\n",
    "model_v3, history, (x_demo, y_demo) = train_model('РОТОР TTE M3')\n",
    "\n",
    "t_demo_v1 = model_v1.predict(np.array([x_demo]))[0]\n",
    "t_demo_v3 = model_v3.predict(np.array([x_demo]))[0]\n",
    "t_one = np.ones(t_demo_v3.shape)\n",
    "t_zero = np.zeros(t_demo_v3.shape)\n",
    "t_half = np.zeros(t_demo_v3.shape) + 0.5\n",
    "t_const = np.zeros(t_demo_v3.shape) + 0.15\n",
    "t_random = np.random.uniform(size=t_demo_v3.shape)\n",
    "\n",
    "if 'val_loss' in pd.DataFrame(history.history).columns:\n",
    "    px.line(history.history, y=['loss', 'val_loss']).show()\n",
    "    px.line(history.history, y=['mae', 'val_mae']).show()\n",
    "else:\n",
    "    px.line(history.history, y=['loss']).show()\n",
    "    px.line(history.history, y=['mae']).show()\n",
    "\n",
    "score_demo_v1 = wrmse_metric(pd.DataFrame(y_demo), pd.DataFrame(t_demo_v1))\n",
    "score_demo_v3 = wrmse_metric(pd.DataFrame(y_demo), pd.DataFrame(t_demo_v3))\n",
    "score_one = wrmse_metric(pd.DataFrame(y_demo), pd.DataFrame(t_one))\n",
    "score_half = wrmse_metric(pd.DataFrame(y_demo), pd.DataFrame(t_half))\n",
    "score_const = wrmse_metric(pd.DataFrame(y_demo), pd.DataFrame(t_const))\n",
    "score_zero = wrmse_metric(pd.DataFrame(y_demo), pd.DataFrame(t_zero))\n",
    "score_random = wrmse_metric(pd.DataFrame(y_demo), pd.DataFrame(t_random))\n",
    "print(\n",
    "    f'score_demo_v1 = {score_demo_v1}\\n'\n",
    "    f'score_demo_v3 = {score_demo_v3}\\n'\n",
    "    f'score_one = {score_one}\\n'\n",
    "    f'score_half = {score_half}\\n'\n",
    "    f'score_const = {score_const}\\n'\n",
    "    f'score_zero = {score_zero}\\n'\n",
    "    f'score_random = {score_random}\\n'\n",
    ")\n",
    "px.line(pd.DataFrame(x_demo)).show()\n",
    "\n",
    "out_x = pd.DataFrame(x_demo, columns=x_structure.index)\n",
    "out_y = pd.DataFrame(y_demo, columns=['y']) \\\n",
    "    .merge(pd.DataFrame(t_demo_v1, columns=['t_demo_v1']), left_index=True, right_index=True) \\\n",
    "    .merge(pd.DataFrame(t_demo_v3, columns=['t_demo_v3']), left_index=True, right_index=True)\n",
    "\n",
    "px.line(out_x)\n",
    "px.line(out_y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def validate_model(target_place_name_and_type, machine):\n",
    "    model = keras.models.load_model(f'../dist/models/{target_place_name_and_type}.h5', compile=False)\n",
    "    right = y_train_tte_1h.set_index(['ИМЯ МАШИНЫ', 'DT'])[[target_place_name_and_type]].astype('float64') / MAX_TTE\n",
    "\n",
    "    input_df = left_train.loc[machine].astype('float64').ffill()\n",
    "    result = pd.DataFrame(index=right.loc[machine].index)\n",
    "    result['ПРОГНОЗ'] = 0\n",
    "\n",
    "    x = 0\n",
    "    while x < len(input_df) - 24*7 - 24:\n",
    "        window = input_df.iloc[x:x+24*7]\n",
    "        if len(window) < 24:\n",
    "            break\n",
    "        input = np.array([window])\n",
    "        output = model.predict(input, verbose=0)\n",
    "        result['ПРОГНОЗ'].iloc[x+24*7:x+24*7+24] = output[0][-24:].reshape((24))\n",
    "\n",
    "        print(\"{:3.2f}%\".format(100 * x / len(input_df)))\n",
    "        x += 24\n",
    "\n",
    "model_v1 = keras.models.load_model(f'../dist/models/УЛИТА TTE M3.h5', compile=False)\n",
    "validate_model('УЛИТА TTE M3', 'ЭКСГАУСТЕР А/М №4')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submission1_ref = pd.read_excel('../data/source/sample_submission/submission_1.xlsx', index_col=0)\n",
    "submission2_ref = pd.read_parquet('../data/source/sample_submission/sample_submission_2.parquet')\n",
    "submission3_ref = pd.read_parquet('../data/source/sample_submission/sample_submission_3.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_test = pd.read_parquet('../data/source/X_test.parquet')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# submission1 = submission1_ref.copy()\n",
    "# submission1['machine'] = np.NaN\n",
    "# submission1['tm'] = np.NaN\n",
    "# submission2 = pd.DataFrame(index=x_test.index, columns=submission2_ref.columns)\n",
    "# submission3 = pd.DataFrame(index=x_test.index, columns=submission3_ref.columns)\n",
    "\n",
    "def apply_model(target_place_name):\n",
    "    submission2_slice_path = f'../dist/submission2/{place}.parquet'\n",
    "    submission3_slice_path = f'../dist/submission3/{place}.parquet'\n",
    "    if os.path.isfile(submission2_slice_path) and os.path.isfile(submission3_slice_path):\n",
    "        return\n",
    "\n",
    "    submission2_slice = pd.DataFrame(index=x_test.index)\n",
    "    submission3_slice = pd.DataFrame(index=x_test.index)\n",
    "\n",
    "    print(str(datetime.now()) + ' -- ' + target_place_name)\n",
    "    for machine in y_structure.columns:\n",
    "        prediction_field_m1 = f'{target_place_name} TTE M1'\n",
    "        prediction_field_m3 = f'{target_place_name} TTE M3'\n",
    "        model_m1 = keras.models.load_model(f'../dist/models/{prediction_field_m1}.h5', compile=False)\n",
    "        model_m3 = keras.models.load_model(f'../dist/models/{prediction_field_m3}.h5', compile=False)\n",
    "        y_name = y_structure[machine].loc[target_place_name]\n",
    "        if y_name not in submission2_ref.columns:\n",
    "            continue\n",
    "\n",
    "        input_df = left_test.loc[machine].astype('float64').ffill()\n",
    "        input_raw_df = left_test_raw.loc[machine].astype('float64')\n",
    "        result = pd.DataFrame(index=left_test.loc[machine].index, columns=[prediction_field_m1, prediction_field_m3])\n",
    "\n",
    "        x = 0\n",
    "        while x < len(input_df) - 24*7 - 24:\n",
    "            window = input_df.iloc[x:x+24*7]\n",
    "            if len(window) < 24:\n",
    "                break\n",
    "            input = np.array([window])\n",
    "            output_m1 = model_m1.predict(input, verbose=0)\n",
    "            output_m3 = model_m3.predict(input, verbose=0)\n",
    "            result[prediction_field_m1].iloc[x+24*7:x+24*7+24] = output_m1[0][-24:].reshape((24))\n",
    "            result[prediction_field_m3].iloc[x+24*7:x+24*7+24] = output_m3[0][-24:].reshape((24))\n",
    "            x += 24\n",
    "\n",
    "        upsampled = result.rolling(72).mean().resample('10s').interpolate().fillna(1)\n",
    "        submission2_slice[y_name] = upsampled[prediction_field_m3].map(lambda x: 1 if x < 0.2 else 0)\n",
    "        submission3_slice[y_name] = upsampled[prediction_field_m1] * MAX_TTE\n",
    "\n",
    "    submission2_slice.to_parquet(submission2_slice_path)\n",
    "    submission3_slice.to_parquet(submission3_slice_path)\n",
    "\n",
    "for place in y_structure.index:\n",
    "    apply_model(place)\n",
    "\n",
    "# for place in ['РОТОР']:\n",
    "#     for machine in ['ЭКСГАУСТЕР А/М №4']:\n",
    "#         apply_model(place, machine)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
